{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "1. Checking 2018 file\n",
    "2. Checking 2013 file \n",
    "3. Indicator preparation \n",
    "4. Checking the rest of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariacarrasco/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (196) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read the dataframe - to improve the fact reading dataframes and changing name\n",
    "\n",
    "dft1 = pd.read_csv('./files/LT_2013p_EUSILC.csv')\n",
    "dft2 = pd.read_csv('./files/FR_2013p_EUSILC.csv')\n",
    "dft3 = pd.read_csv('./files/ES_2013p_EUSILC.csv')\n",
    "dft4 = pd.read_csv('./files/DE_2013p_EUSILC.csv')\n",
    "dft5 = pd.read_csv('./files/BG_2013p_EUSILC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar strings con nombres de los ficheros cambiando el identificador del año \n",
    "# Definición de los campos: \n",
    "# pr: prefix - IE: './files/' - string\n",
    "# sb: subfix: IE: '_2013p_EUSILC.csv' - string\n",
    "# cr: country IE: ['LT'...] - list\n",
    "def filelist(st1,st2,cr): \n",
    "    filelist = []\n",
    "    for s in cr:\n",
    "        filename = st1 + s + st2\n",
    "        filelist.append(filename)\n",
    "    return filelist\n",
    "\n",
    "# Función para concatenar strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para concatenar los ficheros de los distintos años en un sólo fichero - adaptar y revisar\n",
    "def concatenated_df(df_list):\n",
    "    df_temp = pd.DataFrame()\n",
    "    for file in df_list:\n",
    "        df = pd.read_csv(file)\n",
    "        if df_temp.shape == (0,0):\n",
    "            df_temp = df\n",
    "        else: \n",
    "            df_temp = pd.concat([df_temp,df])\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the code of the countries - funciona\n",
    "cr_list = ['LT','FR','ES','DE','BG']\n",
    "d_filelist = filelist('./files/','_2013p_EUSILC.csv',cr_list) # Ficheros información geográfica año 2004 - 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dft1: 94\n",
      "dft2: 284\n",
      "dft3: 94\n",
      "dft4: 284\n",
      "dft5: 94\n"
     ]
    }
   ],
   "source": [
    "# Some of the dataset have higher number of variables, however this is related to the \n",
    "# fact that the dataframes are related to different years 94 four is the number of expected columns\n",
    "\n",
    "df_list = [dft,dft2,dft3,dft4,dft5]\n",
    "counter = 1 \n",
    "for df in df_list:\n",
    "    print('dft'+ str(counter) + ': ' +str(len(df.columns)))\n",
    "    counter += 1\n",
    "    \n",
    "# Checked - now keep going with variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = dft.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "empty_list = []\n",
    "for df in df_list:\n",
    "    cols = df.columns\n",
    "    for col in cols:\n",
    "        empty_list.append(col)\n",
    "    my_serie = pd.Series(empty_list)\n",
    "my_serie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checked that the n of maximun variables is the maximun variables \n",
    "# of the df with the highest n of variables / columns FR and DE\n",
    "len(my_serie.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now checking the coincidence between the different variables and the names within the datasets \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
